{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsadShibli/Innovative-skills-BD/blob/main/assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V44znqgwHCF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import tqdm, time\n",
        "\n",
        "import glob\n",
        "import random,time\n",
        "\n",
        "import math\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import *\n",
        "from tensorflow.keras.regularizers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNoadJXhwpB8"
      },
      "outputs": [],
      "source": [
        "sample_vid = (tf.ones(shape=(1, 16, 224, 224, 3)))\n",
        "sample_img = (tf.ones(shape=(1, 224, 224, 3)))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sIhUOA0wtfN",
        "outputId": "8a037fa3-f83e-4cfc-8786-c0298e81e10d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch, Frame, Height, Width, Chnanel (1, 16, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "print('Batch, Frame, Height, Width, Chnanel',sample_vid.shape,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSIsAxxiwtjI",
        "outputId": "90ab4e7d-4199-4c99-a833-f5d6026b6d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch, Height, Width, Chnanel (1, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "print('Batch, Height, Width, Chnanel',sample_img.shape,)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PIm081G5Pfpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEM20aJMwtm4",
        "outputId": "ce9010de-88b3-490a-fd05-9d2146cbffa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 224, 224, 1)       28        \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 8)       80        \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 224, 224, 12)      876       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 984 (3.84 KB)\n",
            "Trainable params: 984 (3.84 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# num_parameters =  (krnl*krnl)*channel*filter + bias\n",
        "\n",
        "filters1= 1\n",
        "filters2= 8\n",
        "filters3= 12\n",
        "krnl= 3\n",
        "dropout = 0.3\n",
        "\n",
        "dimn = 224\n",
        "\n",
        "inputs = Input(shape=(dimn, dimn, 3))\n",
        "\n",
        "\n",
        "y1 = Conv2D(filters=filters1,kernel_size=(krnl, krnl), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "\n",
        "y2 = Conv2D(filters=filters2 ,kernel_size=(krnl, krnl), activation='relu', padding='same', kernel_initializer='he_normal', use_bias =True)(y1)\n",
        "\n",
        "y = Conv2D(filters=filters3 ,kernel_size=(krnl, krnl), activation='relu', padding='same', kernel_initializer='he_normal')(y2)\n",
        "\n",
        "#y = BatchNormalization()(inputs)\n",
        "\n",
        "\n",
        "outputs = y\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Assignment 3\n",
        "\n",
        "# q1) Explain the parameter count in the batchnorm layer\n",
        "\n",
        "# In a batch normalization layer:\n",
        "\n",
        "# 1 . Scale (γ): This parameter helps the model adjust the scale or magnitude of each feature.\n",
        "# 2 . Shift (β): This parameter allows the model to shift or offset each feature.\n",
        "# 3 . Moving Mean (μ): This is a running average of feature means during training.\n",
        "# 4 . Moving Variance (σ²): This is a running average of feature variances during training.\n",
        "\n",
        "# If batch normalization is applied to the input layer and the input has 3 channels, then the batch normalization layer has:\n",
        "# Total Parameters = 4 (parameters per feature map) * 3 (number of channels) = 12 parameters.\n",
        "\n",
        "# If batch normalization is applied to y1, and y1 has 1 filter, then the batch normalization layer has:\n",
        "# Total Parameters = 4 (parameters per feature map) * 1 (number of filters) = 4 parameters.\n",
        "\n",
        "# So, the parameter count in the batch normalization layer depends on the number of channels or filters to which it is applied."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment q2) Activation softmax why at the classification layer?"
      ],
      "metadata": {
        "id": "aPlABZ2SNBbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Probability Distribution**: Softmax transforms raw output scores into probability distributions over multiple classes, making it essential for classification tasks.\n",
        "\n",
        "**Sum-to-One**: It ensures that the predicted probabilities sum up to 1, suitable for assigning exclusive class labels to inputs in multi-class classification.\n",
        "\n",
        "**Cross-Entropy Loss**: Softmax pairs well with the cross-entropy loss function, which measures the dissimilarity between predicted and actual class distributions.\n",
        "\n",
        "**Comparative Scores**: Softmax magnifies score differences between classes, aiding in distinguishing between classes by assigning higher probabilities to confident predictions.\n",
        "\n",
        "**Differentiable**: Being differentiable, softmax enables gradient-based optimization, such as backpropagation, for effective weight updates during training.\n",
        "\n",
        "**Logits to Probabilities**: It converts raw logits (network outputs) into interpretable class probabilities, suitable for applications requiring probability estimates.\n",
        "\n",
        "**Decision Making**: Softmax simplifies decision-making by selecting the class with the highest probability, offering a clear decision boundary.\n",
        "\n",
        "**Multiclass Support**: It handles problems with more than two classes, making it versatile for various classification tasks.\n",
        "\n",
        "**Standard Choice**: Softmax is the standard choice for the final classification layer due to its ability to convert raw scores into meaningful class probabilities and its versatility in handling multi-class scenarios."
      ],
      "metadata": {
        "id": "OFHO4YtANEfa"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}